"""
í†µí•© TensorFlow 2.x ëª¨ë¸ ë³€í™˜ê¸°
ëª¨ë“  DuoPet AI ëª¨ë¸ì„ TF 2.x í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""
import os
import json
import tensorflow as tf
import numpy as np
from pathlib import Path
import h5py
from typing import Dict, Any, Optional, Tuple
import shutil

# TensorFlow 2.x ì„¤ì •
tf.config.run_functions_eagerly(True)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

class UnifiedModelConverter:
    """í†µí•© ëª¨ë¸ ë³€í™˜ê¸°"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.models_dir = self.project_root / "models" / "health_diagnosis"
        self.backup_dir = self.project_root / "models" / "backup"
        self.conversion_log = []
        
    def backup_original_models(self):
        """ì›ë³¸ ëª¨ë¸ ë°±ì—…"""
        print("ðŸ“¦ ì›ë³¸ ëª¨ë¸ ë°±ì—… ì¤‘...")
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        # ë°±ì—…í•  ëª¨ë¸ ëª©ë¡
        models_to_backup = [
            "eye_disease/best_grouped_model.keras",
            "eye_disease/best_grouped_model_fixed.h5",
            "eye_disease/eye_disease_fixed.h5",
            "bcs/bcs_efficientnet_v1.h5",
            "skin_disease/classification/cat_binary/cat_binary_model.h5",
            "skin_disease/classification/dog_binary/dog_binary_model.h5",
            "skin_disease/classification/dog_multi_136/dog_multi_136_model.h5",
            "skin_disease/classification/dog_multi_456/dog_multi_456_model.h5"
        ]
        
        for model_path in models_to_backup:
            src = self.models_dir / model_path
            if src.exists():
                dst = self.backup_dir / model_path
                dst.parent.mkdir(parents=True, exist_ok=True)
                if not dst.exists():
                    shutil.copy2(src, dst)
                    print(f"  âœ“ ë°±ì—…: {model_path}")
    
    def analyze_model_structure(self, model_path: Path) -> Dict[str, Any]:
        """ëª¨ë¸ êµ¬ì¡° ë¶„ì„"""
        info = {
            "path": str(model_path),
            "exists": model_path.exists(),
            "size_mb": 0,
            "format": "unknown",
            "layers": [],
            "input_shape": None,
            "output_shape": None,
            "total_params": 0,
            "issues": []
        }
        
        if not model_path.exists():
            info["issues"].append("File not found")
            return info
        
        info["size_mb"] = model_path.stat().st_size / (1024 * 1024)
        
        try:
            # H5 íŒŒì¼ ë¶„ì„
            with h5py.File(model_path, 'r') as f:
                info["format"] = "h5"
                
                # êµ¬ì¡° í™•ì¸
                if 'model_config' in f.attrs:
                    config = json.loads(f.attrs['model_config'])
                    info["keras_version"] = f.attrs.get('keras_version', 'Unknown').decode() if hasattr(f.attrs.get('keras_version', 'Unknown'), 'decode') else str(f.attrs.get('keras_version', 'Unknown'))
                    
                # ê°€ì¤‘ì¹˜ êµ¬ì¡° í™•ì¸
                if 'model_weights' in f:
                    def count_weights(name, obj):
                        if isinstance(obj, h5py.Dataset):
                            info["total_params"] += obj.size
                    f['model_weights'].visititems(count_weights)
                    
        except Exception as e:
            info["issues"].append(f"H5 analysis error: {str(e)}")
        
        # ëª¨ë¸ ë¡œë”© ì‹œë„
        try:
            model = tf.keras.models.load_model(str(model_path), compile=False)
            info["input_shape"] = model.input_shape
            info["output_shape"] = model.output_shape
            info["layers"] = [(l.name, l.__class__.__name__) for l in model.layers[:10]]
            
            # Normalization layer í™•ì¸
            norm_layers = [l for l in model.layers if 'normalization' in l.name.lower()]
            if norm_layers:
                info["issues"].append(f"Contains {len(norm_layers)} normalization layers")
                
        except Exception as e:
            info["issues"].append(f"Model loading error: {str(e)}")
            
        return info
    
    def convert_eye_disease_model(self) -> bool:
        """ëˆˆ ì§ˆí™˜ ëª¨ë¸ ë³€í™˜"""
        print("\nðŸ‘ï¸ ëˆˆ ì§ˆí™˜ ëª¨ë¸ ë³€í™˜ ì‹œìž‘...")
        
        # ì´ë¯¸ ë³€í™˜ëœ ëª¨ë¸ ì‚¬ìš©
        src_path = self.models_dir / "eye_disease" / "eye_disease_fixed.h5"
        dst_path = self.models_dir / "eye_disease" / "eye_disease_tf2_unified.h5"
        
        if not src_path.exists():
            print("  âŒ ì†ŒìŠ¤ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        try:
            # ëª¨ë¸ ë¡œë“œ
            model = tf.keras.models.load_model(str(src_path), compile=False)
            
            # ìž¬ì»´íŒŒì¼ (TF 2.x ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©)
            model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                loss='categorical_crossentropy',
                metrics=['accuracy']
            )
            
            # ì €ìž¥
            model.save(str(dst_path), save_format='h5')
            
            # ê²€ì¦
            test_input = np.random.randn(1, 224, 224, 3).astype(np.float32)
            output = model.predict(test_input)
            
            print(f"  âœ“ ë³€í™˜ ì™„ë£Œ: {dst_path.name}")
            print(f"  âœ“ ì¶œë ¥ shape: {output.shape}")
            
            self.conversion_log.append({
                "model": "eye_disease",
                "status": "success",
                "output_path": str(dst_path)
            })
            
            return True
            
        except Exception as e:
            print(f"  âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
            self.conversion_log.append({
                "model": "eye_disease",
                "status": "failed",
                "error": str(e)
            })
            return False
    
    def convert_bcs_model(self) -> bool:
        """BCS ëª¨ë¸ ë³€í™˜"""
        print("\nðŸ• BCS ëª¨ë¸ ë³€í™˜ ì‹œìž‘...")
        
        src_path = self.models_dir / "bcs" / "bcs_efficientnet_v1.h5"
        dst_path = self.models_dir / "bcs" / "bcs_tf2_unified.h5"
        
        if not src_path.exists():
            print("  âŒ ì†ŒìŠ¤ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        try:
            # Custom objects ì •ì˜
            custom_objects = {
                'swish': tf.nn.swish,
                'Swish': tf.keras.layers.Activation(tf.nn.swish)
            }
            
            # ëª¨ë¸ ë¡œë“œ
            model = tf.keras.models.load_model(
                str(src_path), 
                custom_objects=custom_objects,
                compile=False
            )
            
            # ìž¬ì»´íŒŒì¼
            model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                loss='categorical_crossentropy',
                metrics=['accuracy']
            )
            
            # ì €ìž¥
            model.save(str(dst_path), save_format='h5')
            
            # ê²€ì¦
            test_input = np.random.randn(1, 224, 224, 3).astype(np.float32)
            output = model.predict(test_input)
            
            print(f"  âœ“ ë³€í™˜ ì™„ë£Œ: {dst_path.name}")
            print(f"  âœ“ ì¶œë ¥ shape: {output.shape}")
            
            self.conversion_log.append({
                "model": "bcs",
                "status": "success",
                "output_path": str(dst_path)
            })
            
            return True
            
        except Exception as e:
            print(f"  âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
            self.conversion_log.append({
                "model": "bcs",
                "status": "failed",
                "error": str(e)
            })
            return False
    
    def convert_skin_disease_model(self, model_type: str) -> bool:
        """í”¼ë¶€ ì§ˆí™˜ ëª¨ë¸ ë³€í™˜"""
        print(f"\nðŸ¾ í”¼ë¶€ ì§ˆí™˜ ëª¨ë¸ ë³€í™˜: {model_type}")
        
        # ì´ë¯¸ ë³€í™˜ëœ perfect ë²„ì „ ì‚¬ìš©
        src_path = self.models_dir / "skin_disease" / "classification" / model_type / f"{model_type}_model_tf2_perfect.h5"
        dst_path = self.models_dir / "skin_disease" / "classification" / model_type / f"{model_type}_tf2_unified.h5"
        
        if not src_path.exists():
            # ì›ë³¸ ëª¨ë¸ë¡œ ì‹œë„
            src_path = self.models_dir / "skin_disease" / "classification" / model_type / f"{model_type}_model.h5"
            
        if not src_path.exists():
            print(f"  âŒ ì†ŒìŠ¤ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {src_path}")
            return False
            
        try:
            # ëª¨ë¸ ë¡œë“œ
            model = tf.keras.models.load_model(str(src_path), compile=False)
            
            # ì¶œë ¥ ë ˆì´ì–´ì— ë”°ë¥¸ loss í•¨ìˆ˜ ê²°ì •
            output_shape = model.output_shape[-1]
            if output_shape == 1:
                loss = 'binary_crossentropy'
                metrics = ['accuracy', tf.keras.metrics.AUC(name='auc')]
            else:
                loss = 'categorical_crossentropy'
                metrics = ['accuracy']
            
            # ìž¬ì»´íŒŒì¼
            model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                loss=loss,
                metrics=metrics
            )
            
            # ì €ìž¥
            model.save(str(dst_path), save_format='h5')
            
            # ê²€ì¦
            test_input = np.random.randn(1, 224, 224, 3).astype(np.float32)
            output = model.predict(test_input)
            
            print(f"  âœ“ ë³€í™˜ ì™„ë£Œ: {dst_path.name}")
            print(f"  âœ“ ì¶œë ¥ shape: {output.shape}")
            
            self.conversion_log.append({
                "model": f"skin_{model_type}",
                "status": "success",
                "output_path": str(dst_path)
            })
            
            return True
            
        except Exception as e:
            print(f"  âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
            self.conversion_log.append({
                "model": f"skin_{model_type}",
                "status": "failed",
                "error": str(e)
            })
            return False
    
    def run_full_conversion(self):
        """ì „ì²´ ëª¨ë¸ ë³€í™˜ ì‹¤í–‰"""
        print("ðŸš€ í†µí•© TensorFlow 2.x ëª¨ë¸ ë³€í™˜ ì‹œìž‘")
        print("=" * 60)
        
        # 1. ë°±ì—…
        self.backup_original_models()
        
        # 2. í˜„ìž¬ ëª¨ë¸ ìƒíƒœ ë¶„ì„
        print("\nðŸ“Š í˜„ìž¬ ëª¨ë¸ ìƒíƒœ ë¶„ì„...")
        models_to_analyze = [
            "eye_disease/eye_disease_fixed.h5",
            "bcs/bcs_efficientnet_v1.h5",
            "skin_disease/classification/cat_binary/cat_binary_model.h5",
            "skin_disease/classification/dog_binary/dog_binary_model.h5",
            "skin_disease/classification/dog_multi_136/dog_multi_136_model.h5",
            "skin_disease/classification/dog_multi_456/dog_multi_456_model.h5"
        ]
        
        for model_path in models_to_analyze:
            full_path = self.models_dir / model_path
            info = self.analyze_model_structure(full_path)
            print(f"\n  {model_path}:")
            print(f"    - Size: {info['size_mb']:.1f} MB")
            print(f"    - Format: {info['format']}")
            if info['issues']:
                print(f"    - Issues: {', '.join(info['issues'])}")
        
        # 3. ëª¨ë¸ë³„ ë³€í™˜
        print("\nðŸ”§ ëª¨ë¸ ë³€í™˜ ì‹œìž‘...")
        
        # ëˆˆ ì§ˆí™˜ ëª¨ë¸
        self.convert_eye_disease_model()
        
        # BCS ëª¨ë¸
        self.convert_bcs_model()
        
        # í”¼ë¶€ ì§ˆí™˜ ëª¨ë¸ë“¤
        skin_models = ["cat_binary", "dog_binary", "dog_multi_136", "dog_multi_456"]
        for model_type in skin_models:
            self.convert_skin_disease_model(model_type)
        
        # 4. ë³€í™˜ ê²°ê³¼ ìš”ì•½
        print("\nðŸ“‹ ë³€í™˜ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        
        success_count = sum(1 for log in self.conversion_log if log['status'] == 'success')
        failed_count = sum(1 for log in self.conversion_log if log['status'] == 'failed')
        
        print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
        
        # ë³€í™˜ ë¡œê·¸ ì €ìž¥
        log_path = self.project_root / "conversion_log.json"
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(self.conversion_log, f, indent=2, ensure_ascii=False)
        
        print(f"\nðŸ“ ë³€í™˜ ë¡œê·¸ ì €ìž¥: {log_path}")
        
        return success_count > 0

if __name__ == "__main__":
    converter = UnifiedModelConverter()
    converter.run_full_conversion()