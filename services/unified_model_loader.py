"""
í†µí•© ëª¨ë¸ ë¡œë”
TensorFlow 2.x í˜¸í™˜ì„±ì„ ë³´ì¥í•˜ê³  ê·¸ë˜í”„ ì¶©ëŒì„ ë°©ì§€í•˜ëŠ” í†µí•© ëª¨ë¸ ë¡œë”© ì‹œìŠ¤í…œ
"""
import os
import gc
import json
import threading
from pathlib import Path
from typing import Dict, Any, Optional, Union
from contextlib import contextmanager
import numpy as np
import tensorflow as tf
from datetime import datetime

# TensorFlow ì„¤ì •
tf.config.run_functions_eagerly(True)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

class ModelContainer:
    """ê°œë³„ ëª¨ë¸ì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ"""
    
    def __init__(self, model_name: str, model_path: Path, model_type: str):
        self.model_name = model_name
        self.model_path = model_path
        self.model_type = model_type
        self.model = None
        self.graph = None
        self.session = None
        self.loaded = False
        self.last_used = None
        self.load_count = 0
        self.error_count = 0
        
    def load(self, custom_objects: Dict = None):
        """ëª¨ë¸ ë¡œë“œ (ê²©ë¦¬ëœ ê·¸ë˜í”„ ì‚¬ìš©)"""
        try:
            # ìƒˆë¡œìš´ ê·¸ë˜í”„ ìƒì„±
            self.graph = tf.Graph()
            
            with self.graph.as_default():
                # ëª¨ë¸ ë¡œë“œ
                self.model = tf.keras.models.load_model(
                    str(self.model_path),
                    custom_objects=custom_objects or {},
                    compile=False
                )
                
                # ëª¨ë¸ ì»´íŒŒì¼
                self._compile_model()
                
            self.loaded = True
            self.load_count += 1
            self.last_used = datetime.now()
            
            return True
            
        except Exception as e:
            self.error_count += 1
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({self.model_name}): {e}")
            return False
    
    def _compile_model(self):
        """ëª¨ë¸ íƒ€ì…ì— ë”°ë¥¸ ì»´íŒŒì¼"""
        if self.model_type == "eye_disease":
            self.model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                loss='categorical_crossentropy',
                metrics=['accuracy']
            )
        elif self.model_type == "bcs":
            self.model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                loss='categorical_crossentropy',
                metrics=['accuracy']
            )
        elif "binary" in self.model_type:
            self.model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                loss='binary_crossentropy',
                metrics=['accuracy', tf.keras.metrics.AUC()]
            )
        else:  # multi-class
            self.model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                loss='categorical_crossentropy',
                metrics=['accuracy']
            )
    
    def predict(self, input_data: np.ndarray) -> np.ndarray:
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        if not self.loaded or self.model is None:
            raise RuntimeError(f"ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {self.model_name}")
        
        with self.graph.as_default():
            predictions = self.model.predict(input_data, verbose=0)
        
        self.last_used = datetime.now()
        return predictions
    
    def unload(self):
        """ëª¨ë¸ ì–¸ë¡œë“œ ë° ë©”ëª¨ë¦¬ ì •ë¦¬"""
        if self.model is not None:
            del self.model
            self.model = None
        
        if self.graph is not None:
            del self.graph
            self.graph = None
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        gc.collect()
        tf.keras.backend.clear_session()
        
        self.loaded = False


class UnifiedModelLoader:
    """í†µí•© ëª¨ë¸ ë¡œë”"""
    
    def __init__(self, models_dir: str = None):
        self.models_dir = Path(models_dir or "models/health_diagnosis")
        self.model_containers: Dict[str, ModelContainer] = {}
        self.model_configs = self._load_model_configs()
        self.custom_objects = {
            'swish': tf.nn.swish,
            'Swish': tf.nn.swish,
            'silu': tf.nn.silu,
        }
        self._lock = threading.Lock()
        self.max_loaded_models = 3  # ë™ì‹œì— ë¡œë“œí•  ìµœëŒ€ ëª¨ë¸ ìˆ˜
        
    def _load_model_configs(self) -> Dict[str, Dict]:
        """ëª¨ë¸ ì„¤ì • ë¡œë“œ"""
        configs = {
            "eye_disease": {
                "path": "eye_disease/eye_disease_tf2_complete.h5",
                "fallback_paths": [
                    "eye_disease/eye_disease_fixed.h5",
                    "eye_disease/best_grouped_model_fixed.h5"
                ],
                "type": "eye_disease",
                "input_shape": (224, 224, 3),
                "output_classes": 5,
                "preprocessing": "efficientnet"
            },
            "bcs": {
                "path": "bcs/bcs_tf2_unified.h5",
                "fallback_paths": [
                    "bcs/bcs_efficientnet_v1.h5"
                ],
                "type": "bcs",
                "input_shape": (224, 224, 3),
                "output_classes": 3,
                "preprocessing": "standard"
            },
            "skin_cat_binary": {
                "path": "skin_disease/classification/cat_binary/cat_binary_tf2_unified.h5",
                "fallback_paths": [
                    "skin_disease/classification/cat_binary/cat_binary_model_tf2_perfect.h5",
                    "skin_disease/classification/cat_binary/cat_binary_model.h5"
                ],
                "type": "skin_binary",
                "input_shape": (224, 224, 3),
                "output_classes": 1,
                "preprocessing": "mobilenet"
            },
            "skin_dog_binary": {
                "path": "skin_disease/classification/dog_binary/dog_binary_tf2_unified.h5",
                "fallback_paths": [
                    "skin_disease/classification/dog_binary/dog_binary_model_tf2_perfect.h5",
                    "skin_disease/classification/dog_binary/dog_binary_model.h5"
                ],
                "type": "skin_binary",
                "input_shape": (224, 224, 3),
                "output_classes": 1,
                "preprocessing": "mobilenet"
            },
            "skin_dog_multi_136": {
                "path": "skin_disease/classification/dog_multi_136/dog_multi_136_tf2_unified.h5",
                "fallback_paths": [
                    "skin_disease/classification/dog_multi_136/dog_multi_136_model_tf2_perfect.h5",
                    "skin_disease/classification/dog_multi_136/dog_multi_136_model.h5"
                ],
                "type": "skin_multi",
                "input_shape": (224, 224, 3),
                "output_classes": 3,
                "preprocessing": "mobilenet"
            },
            "skin_dog_multi_456": {
                "path": "skin_disease/classification/dog_multi_456/dog_multi_456_tf2_unified.h5",
                "fallback_paths": [
                    "skin_disease/classification/dog_multi_456/dog_multi_456_model_tf2_perfect.h5",
                    "skin_disease/classification/dog_multi_456/dog_multi_456_model.h5"
                ],
                "type": "skin_multi",
                "input_shape": (224, 224, 3),
                "output_classes": 3,
                "preprocessing": "mobilenet"
            }
        }
        
        return configs
    
    def _find_available_model_path(self, config: Dict) -> Optional[Path]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°"""
        # ë©”ì¸ ê²½ë¡œ í™•ì¸
        main_path = self.models_dir / config["path"]
        if main_path.exists():
            return main_path
        
        # í´ë°± ê²½ë¡œë“¤ í™•ì¸
        for fallback in config.get("fallback_paths", []):
            fallback_path = self.models_dir / fallback
            if fallback_path.exists():
                print(f"  âš ï¸ í´ë°± ê²½ë¡œ ì‚¬ìš©: {fallback}")
                return fallback_path
        
        return None
    
    def _manage_memory(self):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ - ì˜¤ë˜ëœ ëª¨ë¸ ì–¸ë¡œë“œ"""
        with self._lock:
            loaded_models = [
                (name, container) 
                for name, container in self.model_containers.items() 
                if container.loaded
            ]
            
            # ë¡œë“œëœ ëª¨ë¸ì´ ìµœëŒ€ì¹˜ë¥¼ ì´ˆê³¼í•˜ë©´
            if len(loaded_models) >= self.max_loaded_models:
                # ê°€ì¥ ì˜¤ë˜ ì‚¬ìš©í•˜ì§€ ì•Šì€ ëª¨ë¸ ì°¾ê¸°
                loaded_models.sort(key=lambda x: x[1].last_used or datetime.min)
                
                # ê°€ì¥ ì˜¤ë˜ëœ ëª¨ë¸ ì–¸ë¡œë“œ
                oldest_name, oldest_container = loaded_models[0]
                print(f"  ğŸ—‘ï¸ ë©”ëª¨ë¦¬ ê´€ë¦¬: {oldest_name} ì–¸ë¡œë“œ")
                oldest_container.unload()
    
    @contextmanager
    def get_model(self, model_name: str):
        """ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        try:
            # ëª¨ë¸ ë¡œë“œ í™•ì¸
            if model_name not in self.model_containers:
                if not self._load_model(model_name):
                    raise RuntimeError(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_name}")
            
            container = self.model_containers[model_name]
            
            # ëª¨ë¸ì´ ì–¸ë¡œë“œë˜ì—ˆë‹¤ë©´ ë‹¤ì‹œ ë¡œë“œ
            if not container.loaded:
                if not container.load(self.custom_objects):
                    raise RuntimeError(f"ëª¨ë¸ ì¬ë¡œë“œ ì‹¤íŒ¨: {model_name}")
            
            yield container
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ({model_name}): {e}")
            raise
    
    def _load_model(self, model_name: str) -> bool:
        """ëª¨ë¸ ë¡œë“œ"""
        with self._lock:
            if model_name not in self.model_configs:
                print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: {model_name}")
                return False
            
            config = self.model_configs[model_name]
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°
            model_path = self._find_available_model_path(config)
            if not model_path:
                print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_name}")
                return False
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬
            self._manage_memory()
            
            # ëª¨ë¸ ì»¨í…Œì´ë„ˆ ìƒì„±
            container = ModelContainer(
                model_name=model_name,
                model_path=model_path,
                model_type=config["type"]
            )
            
            # ëª¨ë¸ ë¡œë“œ
            if container.load(self.custom_objects):
                self.model_containers[model_name] = container
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                return True
            
            return False
    
    def predict(self, model_name: str, input_data: np.ndarray) -> Dict[str, Any]:
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        try:
            with self.get_model(model_name) as container:
                # ì „ì²˜ë¦¬
                processed_input = self._preprocess_input(
                    input_data, 
                    self.model_configs[model_name]["preprocessing"]
                )
                
                # ì˜ˆì¸¡
                predictions = container.predict(processed_input)
                
                # í›„ì²˜ë¦¬
                result = self._postprocess_output(
                    predictions,
                    model_name,
                    self.model_configs[model_name]
                )
                
                return {
                    "status": "success",
                    "model": model_name,
                    "predictions": result,
                    "raw_output": predictions.tolist()
                }
                
        except Exception as e:
            return {
                "status": "error",
                "model": model_name,
                "error": str(e)
            }
    
    def _preprocess_input(self, input_data: np.ndarray, preprocessing: str) -> np.ndarray:
        """ì…ë ¥ ì „ì²˜ë¦¬"""
        if preprocessing == "efficientnet":
            return tf.keras.applications.efficientnet.preprocess_input(input_data)
        elif preprocessing == "mobilenet":
            return tf.keras.applications.mobilenet_v2.preprocess_input(input_data)
        else:  # standard
            return input_data / 255.0
    
    def _postprocess_output(self, predictions: np.ndarray, model_name: str, config: Dict) -> Dict:
        """ì¶œë ¥ í›„ì²˜ë¦¬"""
        if "binary" in model_name:
            # Binary classification
            prob = float(predictions[0][0])
            return {
                "class": "positive" if prob > 0.5 else "negative",
                "confidence": prob if prob > 0.5 else 1 - prob,
                "probabilities": {"negative": 1 - prob, "positive": prob}
            }
        else:
            # Multi-class classification
            class_idx = int(np.argmax(predictions[0]))
            confidence = float(predictions[0][class_idx])
            
            # í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘
            class_names = self._get_class_names(model_name)
            
            return {
                "class": class_names[class_idx] if class_names else str(class_idx),
                "class_index": class_idx,
                "confidence": confidence,
                "probabilities": {
                    class_names[i] if class_names else str(i): float(prob)
                    for i, prob in enumerate(predictions[0])
                }
            }
    
    def _get_class_names(self, model_name: str) -> Optional[list]:
        """ëª¨ë¸ë³„ í´ë˜ìŠ¤ ì´ë¦„ ë°˜í™˜"""
        class_mappings = {
            "eye_disease": ["ì •ìƒ", "ë°±ë‚´ì¥", "ë…¹ë‚´ì¥", "ë§ë§‰ì§ˆí™˜", "ê°ë§‰ì§ˆí™˜"],
            "bcs": ["ë§ˆë¥¸ ì²´í˜•", "ì •ìƒ ì²´í˜•", "ë¹„ë§Œ ì²´í˜•"],
            "skin_dog_multi_136": ["êµ¬ì§„í”Œë¼í¬", "ë¬´ì¦ìƒ", "ë†í¬ì—¬ë“œë¦„"],
            "skin_dog_multi_456": ["ê³¼ë‹¤ìƒ‰ì†Œì¹¨ì°©", "ê²°ì ˆì¢…ê´´", "ë¯¸ë€ê¶¤ì–‘"]
        }
        
        return class_mappings.get(model_name)
    
    def get_status(self) -> Dict:
        """ë¡œë” ìƒíƒœ ë°˜í™˜"""
        status = {
            "loaded_models": [],
            "available_models": list(self.model_configs.keys()),
            "memory_usage": {},
            "statistics": {
                "total_loads": 0,
                "total_errors": 0
            }
        }
        
        for name, container in self.model_containers.items():
            if container.loaded:
                status["loaded_models"].append({
                    "name": name,
                    "type": container.model_type,
                    "last_used": container.last_used.isoformat() if container.last_used else None,
                    "load_count": container.load_count,
                    "error_count": container.error_count
                })
            
            status["statistics"]["total_loads"] += container.load_count
            status["statistics"]["total_errors"] += container.error_count
        
        return status
    
    def cleanup(self):
        """ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ ë° ì •ë¦¬"""
        print("ğŸ§¹ ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ ì¤‘...")
        
        with self._lock:
            for name, container in self.model_containers.items():
                if container.loaded:
                    container.unload()
                    print(f"  âœ“ {name} ì–¸ë¡œë“œ ì™„ë£Œ")
            
            self.model_containers.clear()
        
        # ì „ì²´ ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        tf.keras.backend.clear_session()
        
        print("âœ… ì •ë¦¬ ì™„ë£Œ")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_model_loader_instance = None

def get_model_loader() -> UnifiedModelLoader:
    """ì‹±ê¸€í†¤ ëª¨ë¸ ë¡œë” ë°˜í™˜"""
    global _model_loader_instance
    if _model_loader_instance is None:
        _model_loader_instance = UnifiedModelLoader()
    return _model_loader_instance