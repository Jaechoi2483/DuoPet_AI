"""
ëˆˆ ì§ˆí™˜ ëª¨ë¸ ê³ ê¸‰ ë³€í™˜ê¸°
Normalization layerì™€ ê°€ì¤‘ì¹˜ ë¬¸ì œë¥¼ ì™„ë²½í•˜ê²Œ í•´ê²°
"""
import os
import tensorflow as tf
import numpy as np
from pathlib import Path
import json
import h5py
import tempfile
import shutil

# TensorFlow 2.x ì„¤ì •
tf.config.run_functions_eagerly(True)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

class AdvancedEyeModelConverter:
    """ëˆˆ ì§ˆí™˜ ëª¨ë¸ ê³ ê¸‰ ë³€í™˜ê¸°"""
    
    def __init__(self):
        self.models_dir = Path("models/health_diagnosis/eye_disease")
        self.original_model_path = self.models_dir / "best_grouped_model.keras"
        self.output_path = self.models_dir / "eye_disease_tf2_complete.h5"
        
    def analyze_original_model(self):
        """ì›ë³¸ ëª¨ë¸ ìƒì„¸ ë¶„ì„"""
        print("ğŸ” ì›ë³¸ ëª¨ë¸ ë¶„ì„ ì¤‘...")
        
        try:
            # H5 íŒŒì¼ êµ¬ì¡° ë¶„ì„
            with h5py.File(self.original_model_path, 'r') as f:
                print("\nğŸ“ H5 íŒŒì¼ êµ¬ì¡°:")
                def print_structure(name, obj, level=0):
                    indent = "  " * level
                    if isinstance(obj, h5py.Dataset):
                        print(f"{indent}{name}: shape={obj.shape}, dtype={obj.dtype}")
                    else:
                        print(f"{indent}{name}/")
                        if hasattr(obj, 'keys'):
                            for key in obj.keys():
                                print_structure(f"{name}/{key}", obj[key], level+1)
                
                for key in f.keys():
                    print_structure(key, f[key])
                
                # ë©”íƒ€ë°ì´í„° í™•ì¸
                if 'model_config' in f.attrs:
                    config = json.loads(f.attrs['model_config'])
                    print(f"\nğŸ“‹ ëª¨ë¸ ì„¤ì •:")
                    print(f"  - Class: {config.get('class_name', 'Unknown')}")
                    print(f"  - Keras version: {f.attrs.get('keras_version', 'Unknown')}")
                    
        except Exception as e:
            print(f"âŒ H5 ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    def create_efficientnet_model_with_fix(self):
        """Normalization ë¬¸ì œë¥¼ í•´ê²°í•œ EfficientNet ëª¨ë¸ ìƒì„±"""
        print("\nğŸ”§ ê°œì„ ëœ ëª¨ë¸ êµ¬ì¡° ìƒì„± ì¤‘...")
        
        # ì…ë ¥ ë ˆì´ì–´
        inputs = tf.keras.Input(shape=(224, 224, 3), name='input_layer')
        
        # Normalization layer ëŒ€ì‹  Lambda layer ì‚¬ìš©
        x = tf.keras.layers.Lambda(
            lambda x: tf.keras.applications.efficientnet.preprocess_input(x),
            name='preprocessing'
        )(inputs)
        
        # EfficientNetB0 ë°±ë³¸ (ê°€ì¤‘ì¹˜ ì—†ì´)
        base_model = tf.keras.applications.EfficientNetB0(
            input_tensor=x,
            include_top=False,
            weights=None,  # ê°€ì¤‘ì¹˜ëŠ” ë‚˜ì¤‘ì— ë³µì‚¬
            input_shape=(224, 224, 3)
        )
        
        # ë°±ë³¸ ì¶œë ¥
        x = base_model.output
        x = tf.keras.layers.GlobalAveragePooling2D(name='global_pooling')(x)
        
        # Dense layers
        x = tf.keras.layers.Dense(128, activation='relu', name='dense_1')(x)
        x = tf.keras.layers.Dropout(0.5, name='dropout_1')(x)
        outputs = tf.keras.layers.Dense(5, activation='softmax', name='predictions')(x)
        
        # ìµœì¢… ëª¨ë¸
        model = tf.keras.Model(inputs=inputs, outputs=outputs, name='eye_disease_model')
        
        return model, base_model
    
    def extract_and_map_weights(self, original_model, new_model, base_model):
        """ì›ë³¸ ëª¨ë¸ì—ì„œ ê°€ì¤‘ì¹˜ ì¶”ì¶œ ë° ë§¤í•‘"""
        print("\nğŸ”„ ê°€ì¤‘ì¹˜ ì¶”ì¶œ ë° ë§¤í•‘ ì¤‘...")
        
        # 1. EfficientNet ë°±ë³¸ ê°€ì¤‘ì¹˜ ë§¤í•‘
        print("  - EfficientNet ë°±ë³¸ ê°€ì¤‘ì¹˜ ë³µì‚¬ ì¤‘...")
        
        # ì›ë³¸ ëª¨ë¸ì—ì„œ EfficientNet ë ˆì´ì–´ ì°¾ê¸°
        efficientnet_layer = None
        for layer in original_model.layers:
            if 'efficientnet' in layer.name.lower():
                efficientnet_layer = layer
                break
        
        if efficientnet_layer:
            # ë°±ë³¸ ê°€ì¤‘ì¹˜ ë³µì‚¬
            try:
                # ë ˆì´ì–´ë³„ë¡œ ê°€ì¤‘ì¹˜ ë³µì‚¬
                for orig_layer, new_layer in zip(efficientnet_layer.layers, base_model.layers):
                    if orig_layer.weights and new_layer.weights:
                        try:
                            new_layer.set_weights(orig_layer.get_weights())
                        except:
                            # shape ë¶ˆì¼ì¹˜ ì‹œ ìŠ¤í‚µ
                            pass
                            
                print("    âœ“ ë°±ë³¸ ê°€ì¤‘ì¹˜ ë³µì‚¬ ì™„ë£Œ")
            except Exception as e:
                print(f"    âš ï¸ ë°±ë³¸ ê°€ì¤‘ì¹˜ ë³µì‚¬ ì¤‘ ì¼ë¶€ ì˜¤ë¥˜: {e}")
        
        # 2. Dense layer ê°€ì¤‘ì¹˜ ë§¤í•‘
        print("  - Dense layer ê°€ì¤‘ì¹˜ ë³µì‚¬ ì¤‘...")
        
        # ë ˆì´ì–´ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
        layer_mapping = {
            'dense': 'dense_1',
            'dense_1': 'dense_1',
            'dropout': 'dropout_1',
            'predictions': 'predictions',
            'dense_2': 'predictions'  # ë‹¤ë¥¸ ê°€ëŠ¥í•œ ì´ë¦„
        }
        
        for orig_layer in original_model.layers:
            mapped_name = layer_mapping.get(orig_layer.name, orig_layer.name)
            
            # ìƒˆ ëª¨ë¸ì—ì„œ í•´ë‹¹ ë ˆì´ì–´ ì°¾ê¸°
            for new_layer in new_model.layers:
                if new_layer.name == mapped_name and orig_layer.weights:
                    try:
                        # ê°€ì¤‘ì¹˜ shape í™•ì¸
                        if len(orig_layer.weights) == len(new_layer.weights):
                            weights_match = True
                            for ow, nw in zip(orig_layer.weights, new_layer.weights):
                                if ow.shape != nw.shape:
                                    weights_match = False
                                    break
                            
                            if weights_match:
                                new_layer.set_weights(orig_layer.get_weights())
                                print(f"    âœ“ {orig_layer.name} â†’ {new_layer.name}")
                            else:
                                print(f"    âš ï¸ Shape ë¶ˆì¼ì¹˜: {orig_layer.name}")
                    except Exception as e:
                        print(f"    âš ï¸ ê°€ì¤‘ì¹˜ ë³µì‚¬ ì‹¤íŒ¨ ({orig_layer.name}): {e}")
    
    def convert_with_weight_preservation(self):
        """ê°€ì¤‘ì¹˜ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ëª¨ë¸ ë³€í™˜"""
        print("\nğŸš€ ê³ ê¸‰ ëª¨ë¸ ë³€í™˜ ì‹œì‘")
        print("=" * 60)
        
        try:
            # 1. ì›ë³¸ ëª¨ë¸ ë¶„ì„
            self.analyze_original_model()
            
            # 2. ì›ë³¸ ëª¨ë¸ ë¡œë“œ
            print("\nğŸ“¥ ì›ë³¸ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # Custom objects ì •ì˜
            custom_objects = {
                'swish': tf.nn.swish,
                'Swish': tf.nn.swish,
            }
            
            # ë¨¼ì € compile=Falseë¡œ ì‹œë„
            try:
                original_model = tf.keras.models.load_model(
                    str(self.original_model_path),
                    custom_objects=custom_objects,
                    compile=False
                )
                print("  âœ“ ì›ë³¸ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            except Exception as e:
                print(f"  âŒ ì§ì ‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # .kerasë¥¼ .h5ë¡œ ë³€í™˜ ì‹œë„
                if self.original_model_path.suffix == '.keras':
                    # ì„ì‹œ h5 íŒŒì¼ë¡œ ë³€í™˜
                    temp_h5 = self.models_dir / "temp_converted.h5"
                    
                    # Keras íŒŒì¼ì„ ì½ì–´ì„œ h5ë¡œ ì €ì¥
                    print("  ğŸ“„ .keras â†’ .h5 ë³€í™˜ ì‹œë„...")
                    model_temp = tf.keras.models.load_model(
                        str(self.original_model_path),
                        compile=False
                    )
                    model_temp.save(str(temp_h5), save_format='h5')
                    
                    # h5 íŒŒì¼ë¡œ ë‹¤ì‹œ ë¡œë“œ
                    original_model = tf.keras.models.load_model(
                        str(temp_h5),
                        custom_objects=custom_objects,
                        compile=False
                    )
                    temp_h5.unlink()  # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    
            # 3. ìƒˆ ëª¨ë¸ ìƒì„±
            new_model, base_model = self.create_efficientnet_model_with_fix()
            
            # 4. ê°€ì¤‘ì¹˜ ë§¤í•‘
            self.extract_and_map_weights(original_model, new_model, base_model)
            
            # 5. ì»´íŒŒì¼
            print("\nğŸ”¨ ëª¨ë¸ ì»´íŒŒì¼ ì¤‘...")
            new_model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                loss='categorical_crossentropy',
                metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=2)]
            )
            
            # 6. ì €ì¥
            print("\nğŸ’¾ ë³€í™˜ëœ ëª¨ë¸ ì €ì¥ ì¤‘...")
            new_model.save(str(self.output_path), save_format='h5')
            
            # 7. ê²€ì¦
            print("\nâœ… ë³€í™˜ ê²€ì¦ ì¤‘...")
            test_input = np.random.randn(2, 224, 224, 3).astype(np.float32)
            
            # ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡
            orig_output = original_model.predict(test_input)
            
            # ìƒˆ ëª¨ë¸ ì˜ˆì¸¡
            new_output = new_model.predict(test_input)
            
            # ì¶œë ¥ ë¹„êµ
            print(f"\nğŸ“Š ì¶œë ¥ ë¹„êµ:")
            print(f"  - ì›ë³¸ ëª¨ë¸ ì¶œë ¥ shape: {orig_output.shape}")
            print(f"  - ìƒˆ ëª¨ë¸ ì¶œë ¥ shape: {new_output.shape}")
            print(f"  - ì¶œë ¥ ì°¨ì´ (MAE): {np.mean(np.abs(orig_output - new_output)):.6f}")
            
            # ëª¨ë¸ ì •ë³´ ì €ì¥
            model_info = {
                "model_name": "eye_disease_model",
                "input_shape": [224, 224, 3],
                "output_classes": 5,
                "class_names": ["ì •ìƒ", "ë°±ë‚´ì¥", "ë…¹ë‚´ì¥", "ë§ë§‰ì§ˆí™˜", "ê°ë§‰ì§ˆí™˜"],
                "preprocessing": "efficientnet",
                "framework": "tensorflow",
                "version": tf.__version__,
                "conversion_date": str(Path().resolve()),
                "original_path": str(self.original_model_path),
                "converted_path": str(self.output_path)
            }
            
            info_path = self.models_dir / "model_info.json"
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(model_info, f, indent=2, ensure_ascii=False)
            
            print(f"\nâœ… ë³€í™˜ ì™„ë£Œ!")
            print(f"  - ì¶œë ¥ íŒŒì¼: {self.output_path}")
            print(f"  - ëª¨ë¸ ì •ë³´: {info_path}")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def test_converted_model(self):
        """ë³€í™˜ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ§ª ë³€í™˜ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
        print("=" * 60)
        
        if not self.output_path.exists():
            print("âŒ ë³€í™˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            # ëª¨ë¸ ë¡œë“œ
            model = tf.keras.models.load_model(str(self.output_path))
            
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸°)
            test_batch = np.random.randint(0, 255, (5, 224, 224, 3), dtype=np.uint8)
            test_batch = test_batch.astype(np.float32)
            
            # ì˜ˆì¸¡
            predictions = model.predict(test_batch)
            
            # ê²°ê³¼ ì¶œë ¥
            print("\nì˜ˆì¸¡ ê²°ê³¼:")
            class_names = ["ì •ìƒ", "ë°±ë‚´ì¥", "ë…¹ë‚´ì¥", "ë§ë§‰ì§ˆí™˜", "ê°ë§‰ì§ˆí™˜"]
            
            for i, pred in enumerate(predictions):
                predicted_class = np.argmax(pred)
                confidence = pred[predicted_class]
                print(f"  ì´ë¯¸ì§€ {i+1}: {class_names[predicted_class]} (ì‹ ë¢°ë„: {confidence:.2%})")
            
            print("\nâœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    converter = AdvancedEyeModelConverter()
    
    # ë³€í™˜ ì‹¤í–‰
    if converter.convert_with_weight_preservation():
        # ë³€í™˜ ì„±ê³µ ì‹œ í…ŒìŠ¤íŠ¸
        converter.test_converted_model()