"""
í”¼ë¶€ ì§ˆí™˜ ëª¨ë¸ì˜ ì •í™•í•œ êµ¬ì¡°ë¥¼ ì¬í˜„í•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ 100% ë³µì›
"""
import os
import tensorflow as tf
import numpy as np
from pathlib import Path
import json
import h5py

# TensorFlow 2.x eager ëª¨ë“œ
tf.config.run_functions_eagerly(True)

def create_exact_model_structure(model_name, input_shape=(224, 224, 3)):
    """ì›ë³¸ê³¼ ì •í™•íˆ ë™ì¼í•œ êµ¬ì¡°ì˜ ëª¨ë¸ ìƒì„±"""
    
    # Input layers - TFOpLambda ëŒ€ì‹  Lambda ì‚¬ìš©
    inputs = tf.keras.Input(shape=input_shape, name='input')
    
    # Preprocessing layers (TFOpLambda ëŒ€ì²´)
    x = tf.keras.layers.Lambda(lambda x: x / 127.5, name='tf_math_truediv')(inputs)
    x = tf.keras.layers.Lambda(lambda x: x - 1.0, name='tf_math_subtract')(x)
    
    # MobileNetV2 ë°±ë³¸
    mobilenet = tf.keras.applications.MobileNetV2(
        input_shape=input_shape,
        include_top=False,
        weights=None,  # ê°€ì¤‘ì¹˜ëŠ” ë‚˜ì¤‘ì— ë³µì›
        input_tensor=x
    )
    mobilenet._name = 'mobilenetv2_1.00_224'
    
    # ë°±ë³¸ ì¶œë ¥
    x = mobilenet.output
    x = tf.keras.layers.GlobalAveragePooling2D(name='global_average_pooling2d')(x)
    
    # Dense ë ˆì´ì–´ - ëª¨ë¸ë³„ë¡œ ë‹¤ë¥¸ ì´ë¦„ ì‚¬ìš©
    if 'binary' in model_name:
        if 'dog' in model_name:
            x = tf.keras.layers.Dense(128, activation='relu', name='dense_2')(x)
            x = tf.keras.layers.Dropout(0.5, name='dropout_1')(x)
            outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='dense_3')(x)
        else:  # cat_binary
            x = tf.keras.layers.Dense(128, activation='relu', name='dense')(x)
            x = tf.keras.layers.Dropout(0.5, name='dropout')(x)
            outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='dense_1')(x)
    else:  # multi class
        if '136' in model_name:
            x = tf.keras.layers.Dense(128, activation='relu', name='dense_4')(x)
            x = tf.keras.layers.Dropout(0.5, name='dropout_2')(x)
            outputs = tf.keras.layers.Dense(3, activation='softmax', name='dense_5')(x)
        else:  # 456
            x = tf.keras.layers.Dense(128, activation='relu', name='dense_6')(x)
            x = tf.keras.layers.Dropout(0.5, name='dropout_3')(x)
            outputs = tf.keras.layers.Dense(3, activation='softmax', name='dense_7')(x)
    
    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='model')
    return model

def load_weights_from_h5(h5_path):
    """H5 íŒŒì¼ì—ì„œ ëª¨ë“  ê°€ì¤‘ì¹˜ ì¶”ì¶œ"""
    weights_dict = {}
    
    with h5py.File(h5_path, 'r') as f:
        if 'model_weights' in f:
            def extract_weights(name, obj):
                if isinstance(obj, h5py.Dataset):
                    # ì „ì²´ ê²½ë¡œ ì €ì¥
                    weights_dict[name] = np.array(obj)
            
            f['model_weights'].visititems(extract_weights)
    
    return weights_dict

def apply_weights_to_model(model, weights_dict):
    """ì¶”ì¶œí•œ ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë¸ì— ì •í™•íˆ ì ìš©"""
    applied_count = 0
    not_found_layers = []
    
    for layer in model.layers:
        if hasattr(layer, 'layers'):  # Functional ëª¨ë¸ì¸ ê²½ìš°
            # MobileNetV2 ë‚´ë¶€ ë ˆì´ì–´ë“¤
            for sub_layer in layer.layers:
                layer_name = sub_layer.name
                weights_found = []
                
                # ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ íƒ€ì…ë“¤
                weight_types = ['kernel:0', 'bias:0', 'depthwise_kernel:0', 
                               'pointwise_kernel:0', 'gamma:0', 'beta:0', 
                               'moving_mean:0', 'moving_variance:0']
                
                for weight_type in weight_types:
                    weight_key = f"mobilenetv2_1.00_224/{layer_name}/{weight_type}"
                    if weight_key in weights_dict:
                        weights_found.append(weights_dict[weight_key])
                
                if weights_found:
                    try:
                        sub_layer.set_weights(weights_found)
                        applied_count += 1
                        print(f"  âœ“ {layer_name}: {len(weights_found)}ê°œ ê°€ì¤‘ì¹˜ ì ìš©")
                    except Exception as e:
                        print(f"  âŒ {layer_name}: ê°€ì¤‘ì¹˜ ì ìš© ì‹¤íŒ¨ - {e}")
        else:
            # ì¼ë°˜ ë ˆì´ì–´
            layer_name = layer.name
            weights_found = []
            
            # kernelê³¼ bias ì°¾ê¸°
            if f"{layer_name}/kernel:0" in weights_dict:
                weights_found.append(weights_dict[f"{layer_name}/kernel:0"])
            if f"{layer_name}/bias:0" in weights_dict:
                weights_found.append(weights_dict[f"{layer_name}/bias:0"])
            
            if weights_found:
                try:
                    layer.set_weights(weights_found)
                    applied_count += 1
                    print(f"  âœ“ {layer_name}: {len(weights_found)}ê°œ ê°€ì¤‘ì¹˜ ì ìš©")
                except Exception as e:
                    print(f"  âŒ {layer_name}: ê°€ì¤‘ì¹˜ ì ìš© ì‹¤íŒ¨ - {e}")
            elif layer.weights:  # ê°€ì¤‘ì¹˜ê°€ ìˆì–´ì•¼ í•˜ëŠ” ë ˆì´ì–´ì¸ë° ëª» ì°¾ì€ ê²½ìš°
                not_found_layers.append(layer_name)
    
    if not_found_layers:
        print(f"\n  âš ï¸ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ì§€ ëª»í•œ ë ˆì´ì–´: {not_found_layers}")
    
    return applied_count

def convert_single_model(model_info):
    """ë‹¨ì¼ ëª¨ë¸ ë³€í™˜ - ì •í™•í•œ ê°€ì¤‘ì¹˜ ë³µì›"""
    print(f"\n{'='*60}")
    print(f"ğŸ“ {model_info['name']} ëª¨ë¸ ë³€í™˜ ì¤‘...")
    
    try:
        # 1. ì›ë³¸ ëª¨ë¸ì—ì„œ ê°€ì¤‘ì¹˜ ì¶”ì¶œ
        print(f"  ğŸ“‚ ê°€ì¤‘ì¹˜ ì¶”ì¶œ ì¤‘: {model_info['original_path']}")
        weights_dict = load_weights_from_h5(model_info['original_path'])
        print(f"  âœ… {len(weights_dict)}ê°œ ê°€ì¤‘ì¹˜ í…ì„œ ì¶”ì¶œ ì™„ë£Œ")
        
        # 2. ì •í™•í•œ êµ¬ì¡°ì˜ ìƒˆ ëª¨ë¸ ìƒì„±
        print(f"  ğŸ—ï¸ ì›ë³¸ê³¼ ë™ì¼í•œ êµ¬ì¡°ì˜ ëª¨ë¸ ìƒì„± ì¤‘...")
        new_model = create_exact_model_structure(model_info['name'])
        print(f"  âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        
        # 3. ê°€ì¤‘ì¹˜ ì ìš©
        print(f"  ğŸ”„ ê°€ì¤‘ì¹˜ ë³µì› ì¤‘...")
        applied_count = apply_weights_to_model(new_model, weights_dict)
        print(f"  âœ… {applied_count}ê°œ ë ˆì´ì–´ì— ê°€ì¤‘ì¹˜ ë³µì› ì™„ë£Œ")
        
        # 4. ì»´íŒŒì¼
        if 'binary' in model_info['name']:
            loss = 'binary_crossentropy'
        else:
            loss = 'categorical_crossentropy'
        
        new_model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss=loss,
            metrics=['accuracy']
        )
        
        # 5. ê²€ì¦ - ì›ë³¸ê³¼ ë™ì¼í•œ ì¶œë ¥ í™•ì¸
        print(f"  ğŸ§ª ê°€ì¤‘ì¹˜ ê²€ì¦ ì¤‘...")
        test_input = np.random.rand(1, 224, 224, 3).astype(np.float32) * 255  # 0-255 ë²”ìœ„
        
        # ì›ë³¸ ëª¨ë¸ ë¡œë“œí•˜ì—¬ ë¹„êµ
        try:
            original_model = tf.keras.models.load_model(
                str(model_info['original_path']), 
                compile=False,
                custom_objects={'TFOpLambda': tf.keras.layers.Lambda}
            )
            original_output = original_model.predict(test_input, verbose=0)
            new_output = new_model.predict(test_input, verbose=0)
            
            # ì¶œë ¥ ë¹„êµ
            output_diff = np.abs(original_output - new_output).max()
            print(f"  âœ… ì›ë³¸ê³¼ì˜ ìµœëŒ€ ì°¨ì´: {output_diff:.6f}")
            
            if output_diff < 0.001:
                print(f"  âœ… ê°€ì¤‘ì¹˜ê°€ ì™„ë²½í•˜ê²Œ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                print(f"  âš ï¸ ì¶œë ¥ì— ì•½ê°„ì˜ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤")
        except Exception as e:
            print(f"  âš ï¸ ì›ë³¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ê²€ì¦ ìŠ¤í‚µ: {e}")
            new_output = new_model.predict(test_input, verbose=0)
        
        print(f"  ğŸ“Š ì¶œë ¥ shape: {new_output.shape}")
        print(f"  ğŸ“Š ì¶œë ¥ ë²”ìœ„: [{new_output.min():.4f}, {new_output.max():.4f}]")
        
        # 6. ì €ì¥
        output_path = str(model_info['original_path']).replace('.h5', '_tf2_restored.h5')
        new_model.save(output_path, save_format='h5')
        print(f"  ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    base_dir = Path("models/health_diagnosis/skin_disease")
    print("ğŸ”§ í”¼ë¶€ ì§ˆí™˜ ëª¨ë¸ ì •í™•í•œ ê°€ì¤‘ì¹˜ ë³µì›")
    
    models_to_convert = [
        {
            "name": "dog_binary",
            "original_path": base_dir / "classification/dog_binary/dog_binary_model.h5"
        },
        {
            "name": "cat_binary", 
            "original_path": base_dir / "classification/cat_binary/cat_binary_model.h5"
        },
        {
            "name": "dog_multi_136",
            "original_path": base_dir / "classification/dog_multi_136/dog_multi_136_model.h5"
        },
        {
            "name": "dog_multi_456",
            "original_path": base_dir / "classification/dog_multi_456/dog_multi_456_model.h5"
        }
    ]
    
    success_count = 0
    
    for model_info in models_to_convert:
        if model_info['original_path'].exists():
            if convert_single_model(model_info):
                success_count += 1
        else:
            print(f"\nâŒ {model_info['name']} ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ë³€í™˜ ê²°ê³¼: {success_count}/{len(models_to_convert)} ì„±ê³µ")
    
    if success_count > 0:
        print("\nâœ¨ ê°€ì¤‘ì¹˜ë¥¼ ì™„ë²½í•˜ê²Œ ë³µì›í•œ TF2 ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
        print("ğŸ“Œ *_tf2_restored.h5 íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
        print("ğŸ¯ ì›ë³¸ ëª¨ë¸ì˜ ëª¨ë“  í•™ìŠµëœ ì§€ì‹ì´ ë³´ì¡´ë˜ì—ˆìŠµë‹ˆë‹¤")
        
        # skin_disease_service.py ì—…ë°ì´íŠ¸ ì•ˆë‚´
        print("\nğŸ“ skin_disease_service.pyì—ì„œ ë‹¤ìŒ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •í•˜ì„¸ìš”:")
        for model_info in models_to_convert:
            tf2_path = str(model_info['original_path']).replace('.h5', '_tf2_restored.h5')
            print(f"   - {Path(tf2_path).name}")

if __name__ == "__main__":
    main()