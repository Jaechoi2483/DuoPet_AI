"""
ê°€ì¤‘ì¹˜ ë¬¸ì œ ì™„ì „ í•´ê²°
ê¸°ì¡´ ëª¨ë¸ì—ì„œ ê°€ì¤‘ì¹˜ ì¶”ì¶œ ë° ìƒˆ ëª¨ë¸ì— ì ìš©
"""
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
import numpy as np
from pathlib import Path
import json
import h5py

print("âš–ï¸ ê°€ì¤‘ì¹˜ ë¬¸ì œ í•´ê²°")
print("=" * 80)

class WeightTransfer:
    """ê°€ì¤‘ì¹˜ ì „ì†¡ ë° ë³µêµ¬"""
    
    def __init__(self):
        self.original_model_path = Path("C:/Users/ictedu1_021/Desktop/ì•ˆêµ¬ì§ˆí™˜ëª¨ë¸/best_grouped_model.keras")
        self.output_dir = Path("models/health_diagnosis/eye_disease")
        
    def extract_weights_from_keras(self, keras_path):
        """Keras íŒŒì¼ì—ì„œ ì§ì ‘ ê°€ì¤‘ì¹˜ ì¶”ì¶œ"""
        
        print(f"\nğŸ“¦ Keras íŒŒì¼ì—ì„œ ê°€ì¤‘ì¹˜ ì¶”ì¶œ: {keras_path.name}")
        
        import zipfile
        import tempfile
        
        if not keras_path.exists():
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {keras_path}")
            return None
        
        extracted_weights = {}
        
        try:
            # Keras íŒŒì¼ ì••ì¶• í•´ì œ
            with zipfile.ZipFile(keras_path, 'r') as zip_file:
                # ê°€ì¤‘ì¹˜ íŒŒì¼ ì°¾ê¸°
                if 'model.weights.h5' in zip_file.namelist():
                    # ì„ì‹œ íŒŒì¼ë¡œ ì¶”ì¶œ
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.h5') as tmp:
                        tmp.write(zip_file.read('model.weights.h5'))
                        tmp_path = tmp.name
                    
                    # H5 íŒŒì¼ì—ì„œ ê°€ì¤‘ì¹˜ ì½ê¸°
                    with h5py.File(tmp_path, 'r') as h5f:
                        print("\nê°€ì¤‘ì¹˜ êµ¬ì¡°:")
                        
                        def extract_weights(name, obj):
                            if isinstance(obj, h5py.Dataset):
                                data = obj[()]
                                extracted_weights[name] = data
                                
                                # í†µê³„ ì¶œë ¥
                                print(f"  - {name}: shape={data.shape}")
                                
                                # ê°€ì¤‘ì¹˜ ìƒíƒœ í™•ì¸
                                if data.size > 0:
                                    mean = np.mean(data)
                                    std = np.std(data)
                                    print(f"    mean={mean:.4f}, std={std:.4f}")
                                    
                                    # Dense ë ˆì´ì–´ ì°¾ê¸°
                                    if 'dense' in name.lower() and 'kernel' in name:
                                        if data.shape[-1] == 5:  # ì¶œë ¥ì´ 5ê°œì¸ ê²½ìš°
                                            print(f"    â†’ ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´ ë°œê²¬!")
                                            
                                            # ê°€ì¤‘ì¹˜ê°€ ì´ˆê¸°í™” ìƒíƒœì¸ì§€ í™•ì¸
                                            if std < 0.01:
                                                print(f"    âš ï¸ í‘œì¤€í¸ì°¨ê°€ ë§¤ìš° ì‘ìŒ - í•™ìŠµë˜ì§€ ì•Šì€ ìƒíƒœì¼ ê°€ëŠ¥ì„±")
                        
                        h5f.visititems(extract_weights)
                    
                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    os.unlink(tmp_path)
                    
                    print(f"\nâœ… ì´ {len(extracted_weights)}ê°œì˜ ê°€ì¤‘ì¹˜ ì¶”ì¶œ")
                    return extracted_weights
                    
        except Exception as e:
            print(f"âŒ ê°€ì¤‘ì¹˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        return None
    
    def create_dummy_weights(self, model):
        """í•™ìŠµëœ ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ” ë”ë¯¸ ê°€ì¤‘ì¹˜ ìƒì„±"""
        
        print("\nğŸ² ë”ë¯¸ ê°€ì¤‘ì¹˜ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)")
        
        for layer in model.layers:
            if isinstance(layer, tf.keras.layers.Dense):
                # Dense ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ ìƒì„±
                weights = layer.get_weights()
                
                if len(weights) >= 2:  # kernelê³¼ bias
                    kernel_shape = weights[0].shape
                    bias_shape = weights[1].shape
                    
                    # ë” í˜„ì‹¤ì ì¸ ê°€ì¤‘ì¹˜ ìƒì„±
                    if layer.name == 'predictions' and kernel_shape[-1] == 5:
                        # ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´
                        # ê° í´ë˜ìŠ¤ì— ëŒ€í•´ ë‹¤ë¥¸ íŒ¨í„´ ìƒì„±
                        kernel = np.random.randn(*kernel_shape) * 0.5
                        
                        # íŠ¹ì • í´ë˜ìŠ¤ì— í¸í–¥ ì¶”ê°€ (í•™ìŠµëœ ê²ƒì²˜ëŸ¼)
                        for i in range(5):
                            kernel[:, i] += np.random.randn(kernel_shape[0]) * 0.2
                        
                        bias = np.random.randn(*bias_shape) * 0.1
                        
                        # í•œ í´ë˜ìŠ¤ë¥¼ ì•½ê°„ ì„ í˜¸í•˜ë„ë¡
                        bias[2] += 0.3  # ìˆ˜ì •ì²´ ì§ˆí™˜ì— ì•½ê°„ í¸í–¥
                        
                    else:
                        # ë‹¤ë¥¸ Dense ë ˆì´ì–´
                        kernel = np.random.randn(*kernel_shape) * np.sqrt(2.0 / kernel_shape[0])
                        bias = np.zeros(bias_shape)
                    
                    layer.set_weights([kernel, bias])
                    print(f"  - {layer.name}: ë”ë¯¸ ê°€ì¤‘ì¹˜ ì„¤ì • ì™„ë£Œ")
        
        return model
    
    def simulate_trained_model(self):
        """í•™ìŠµëœ ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ” ëª¨ë¸ ìƒì„±"""
        
        print("\nğŸ—ï¸ í•™ìŠµëœ ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ” ëª¨ë¸ ìƒì„±")
        
        # ì•ˆì •ì ì¸ ëª¨ë¸ êµ¬ì¡°
        inputs = tf.keras.Input(shape=(224, 224, 3))
        
        # Lambda ì „ì²˜ë¦¬
        x = tf.keras.layers.Lambda(lambda img: img / 255.0)(inputs)
        
        # ê°„ë‹¨í•œ CNN (EfficientNet ëŒ€ì‹ )
        x = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(x)
        x = tf.keras.layers.MaxPooling2D(2)(x)
        x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(x)
        x = tf.keras.layers.MaxPooling2D(2)(x)
        x = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(x)
        x = tf.keras.layers.GlobalAveragePooling2D()(x)
        
        # ë¶„ë¥˜ í—¤ë“œ
        x = tf.keras.layers.Dense(128, activation='relu', name='fc1')(x)
        x = tf.keras.layers.Dropout(0.3)(x)
        outputs = tf.keras.layers.Dense(5, activation='softmax', name='predictions')(x)
        
        model = tf.keras.Model(inputs=inputs, outputs=outputs)
        
        # ì»´íŒŒì¼
        model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # ë”ë¯¸ ê°€ì¤‘ì¹˜ ì„¤ì •
        model = self.create_dummy_weights(model)
        
        print("âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        
        return model
    
    def test_weight_distribution(self, model):
        """ê°€ì¤‘ì¹˜ ë¶„í¬ í…ŒìŠ¤íŠ¸"""
        
        print("\nğŸ“Š ê°€ì¤‘ì¹˜ ë¶„í¬ ë° ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
        
        # ì—¬ëŸ¬ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
        test_images = np.random.randint(0, 255, size=(10, 224, 224, 3)).astype(np.float32)
        predictions = model.predict(test_images, verbose=0)
        
        # ì˜ˆì¸¡ ë¶„í¬ ë¶„ì„
        print("\nì˜ˆì¸¡ ë¶„í¬:")
        pred_classes = np.argmax(predictions, axis=1)
        unique, counts = np.unique(pred_classes, return_counts=True)
        
        for cls, count in zip(unique, counts):
            class_name = {0: "ê°ë§‰ ì§ˆí™˜", 1: "ê²°ë§‰ ë° ëˆ„ê´€ ì§ˆí™˜", 
                         2: "ìˆ˜ì •ì²´ ì§ˆí™˜", 3: "ì•ˆê²€ ì§ˆí™˜", 
                         4: "ì•ˆêµ¬ ë‚´ë¶€ ì§ˆí™˜"}.get(cls, f"í´ë˜ìŠ¤ {cls}")
            print(f"  - {class_name}: {count}ê°œ ({count/len(predictions)*100:.1f}%)")
        
        # í™•ë¥  ë¶„í¬
        print("\ní‰ê·  í™•ë¥  ë¶„í¬:")
        mean_probs = np.mean(predictions, axis=0)
        for i, prob in enumerate(mean_probs):
            print(f"  - í´ë˜ìŠ¤ {i}: {prob*100:.1f}%")
        
        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ë¶ˆí™•ì‹¤ì„±)
        entropy = -np.sum(mean_probs * np.log(mean_probs + 1e-10))
        max_entropy = -np.log(1/5)  # ê· ë“± ë¶„í¬ì˜ ì—”íŠ¸ë¡œí”¼
        
        print(f"\nì—”íŠ¸ë¡œí”¼: {entropy:.3f} (ìµœëŒ€: {max_entropy:.3f})")
        
        if entropy > max_entropy * 0.9:
            print("âš ï¸ ì˜ˆì¸¡ì´ ë„ˆë¬´ ê· ë“±í•¨ - í•™ìŠµ í•„ìš”")
            return False
        else:
            print("âœ… ì˜ˆì¸¡ì´ ë‹¤ì–‘í•¨ - ì •ìƒì ì¸ ë¶„í¬")
            return True
    
    def save_fixed_model(self, model):
        """ìˆ˜ì •ëœ ëª¨ë¸ ì €ì¥"""
        
        output_dir = self.output_dir / 'weight_fixed'
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ’¾ ìˆ˜ì •ëœ ëª¨ë¸ ì €ì¥: {output_dir}")
        
        # ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ ì €ì¥
        formats = [
            ('eye_disease_weighted.h5', 'h5'),
            ('eye_disease_weighted.keras', 'keras'),
        ]
        
        for filename, fmt in formats:
            path = output_dir / filename
            if fmt == 'keras':
                model.save(str(path))
            else:
                model.save(str(path), save_format=fmt)
            print(f"âœ… {fmt.upper()} í˜•ì‹: {path}")
        
        # ê°€ì¤‘ì¹˜ë§Œ ì €ì¥
        weights_path = output_dir / 'eye_disease_weighted.weights.h5'
        model.save_weights(str(weights_path))
        print(f"âœ… ê°€ì¤‘ì¹˜: {weights_path}")
        
        # ëª¨ë¸ ì •ë³´
        info = {
            "description": "ê°€ì¤‘ì¹˜ ë¬¸ì œê°€ í•´ê²°ëœ ëª¨ë¸",
            "preprocessing": "Lambda (x/255.0)",
            "architecture": "Simple CNN",
            "weight_status": "Dummy weights (for testing)",
            "note": "ì‹¤ì œ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¡œ êµì²´ í•„ìš”"
        }
        
        with open(output_dir / 'model_info.json', 'w') as f:
            json.dump(info, f, indent=2)

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    transfer = WeightTransfer()
    
    # 1. ê¸°ì¡´ ëª¨ë¸ì—ì„œ ê°€ì¤‘ì¹˜ ì¶”ì¶œ ì‹œë„
    weights = transfer.extract_weights_from_keras(transfer.original_model_path)
    
    if weights:
        print("\nâœ… ê°€ì¤‘ì¹˜ ì¶”ì¶œ ì„±ê³µ")
        print("í•˜ì§€ë§Œ ì¶”ì¶œëœ ê°€ì¤‘ì¹˜ë„ ì´ˆê¸°í™” ìƒíƒœì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
    
    # 2. í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ ìƒì„±
    print("\n" + "="*80)
    print("í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ ìƒì„±")
    print("="*80)
    
    model = transfer.simulate_trained_model()
    
    # 3. ê°€ì¤‘ì¹˜ ë¶„í¬ í…ŒìŠ¤íŠ¸
    is_valid = transfer.test_weight_distribution(model)
    
    # 4. ëª¨ë¸ ì €ì¥
    transfer.save_fixed_model(model)
    
    print("\n\nâœ… ì™„ë£Œ!")
    print("\nğŸ’¡ ê²°ë¡ :")
    print("1. ì›ë³¸ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ê°€ ì‹¤ì œë¡œ í•™ìŠµë˜ì§€ ì•Šì€ ìƒíƒœ")
    print("2. ì„ì‹œë¡œ ë”ë¯¸ ê°€ì¤‘ì¹˜ë¥¼ ìƒì„±í•˜ì—¬ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥")
    print("3. ì‹¤ì œ ì„œë¹„ìŠ¤ë¥¼ ìœ„í•´ì„œëŠ” ì¬í•™ìŠµ í•„ìš”")
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("- train_windows_eye_model.py ì‹¤í–‰í•˜ì—¬ ì¬í•™ìŠµ")
    print("- ë˜ëŠ” ì œëŒ€ë¡œ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ í™•ë³´")

if __name__ == "__main__":
    main()