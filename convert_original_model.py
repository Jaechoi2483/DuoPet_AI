"""
ì›ë³¸ ì•ˆêµ¬ì§ˆí™˜ ëª¨ë¸ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
í´ë˜ìŠ¤ë§µ ì°¨ì´ì™€ ëª¨ë¸ êµ¬ì¡°ë¥¼ ê³ ë ¤í•œ ì˜¬ë°”ë¥¸ ë³€í™˜
"""
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
import numpy as np
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# TensorFlow 2.x ì„¤ì •
tf.compat.v1.disable_v2_behavior()

def load_original_model_carefully():
    """ì›ë³¸ ëª¨ë¸ì„ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ë¡œë“œ"""
    
    print("ğŸ”§ ì›ë³¸ ëª¨ë¸ ë³€í™˜ ì‹œì‘")
    print("="*80)
    
    # ê²½ë¡œ ì„¤ì •
    import platform
    if platform.system() == "Windows":
        original_model_path = r"C:\Users\ictedu1_021\Desktop\ì•ˆêµ¬ì§ˆí™˜ëª¨ë¸\best_grouped_model.keras"
        original_class_map_path = r"C:\Users\ictedu1_021\Desktop\ì•ˆêµ¬ì§ˆí™˜ëª¨ë¸\class_map.json"
    else:
        original_model_path = "/mnt/c/Users/ictedu1_021/Desktop/ì•ˆêµ¬ì§ˆí™˜ëª¨ë¸/best_grouped_model.keras"
        original_class_map_path = "/mnt/c/Users/ictedu1_021/Desktop/ì•ˆêµ¬ì§ˆí™˜ëª¨ë¸/class_map.json"
    
    # ì›ë³¸ í´ë˜ìŠ¤ë§µ ë¡œë“œ
    with open(original_class_map_path, 'r', encoding='utf-8') as f:
        original_class_map = json.load(f)
    
    print("ğŸ“‹ ì›ë³¸ í´ë˜ìŠ¤ë§µ:")
    for idx, name in original_class_map.items():
        print(f"  {idx}: {name}")
    
    # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í´ë˜ìŠ¤ë§µ
    current_class_map = {
        "0": "ì •ìƒ",
        "1": "ë°±ë‚´ì¥", 
        "2": "ê²°ë§‰ì—¼",
        "3": "ê°ë§‰ê¶¤ì–‘",
        "4": "ê¸°íƒ€ì•ˆêµ¬ì§ˆí™˜"
    }
    
    print("\nğŸ“‹ íƒ€ê²Ÿ í´ë˜ìŠ¤ë§µ:")
    for idx, name in current_class_map.items():
        print(f"  {idx}: {name}")
    
    # í´ë˜ìŠ¤ ë§¤í•‘ ê´€ê³„ ì •ì˜
    class_mapping = {
        # ì›ë³¸ -> í˜„ì¬
        0: 3,  # ê°ë§‰ ì§ˆí™˜ -> ê°ë§‰ê¶¤ì–‘
        1: 2,  # ê²°ë§‰ ë° ëˆ„ê´€ ì§ˆí™˜ -> ê²°ë§‰ì—¼  
        2: 1,  # ìˆ˜ì •ì²´ ì§ˆí™˜ -> ë°±ë‚´ì¥
        3: 4,  # ì•ˆê²€ ì§ˆí™˜ -> ê¸°íƒ€ì•ˆêµ¬ì§ˆí™˜
        4: 4   # ì•ˆêµ¬ ë‚´ë¶€ ì§ˆí™˜ -> ê¸°íƒ€ì•ˆêµ¬ì§ˆí™˜
    }
    
    print("\nğŸ”„ í´ë˜ìŠ¤ ë§¤í•‘:")
    for orig_idx, new_idx in class_mapping.items():
        orig_name = original_class_map[str(orig_idx)]
        new_name = current_class_map[str(new_idx)]
        print(f"  {orig_name} -> {new_name}")
    
    # ëª¨ë¸ ë¡œë“œ ì‹œë„
    print("\nğŸ“¥ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    
    try:
        # Custom objects ì •ì˜
        custom_objects = {
            'swish': tf.nn.swish,
            'Swish': tf.keras.layers.Activation(tf.nn.swish),
            'FixedDropout': tf.keras.layers.Dropout,
            'Functional': tf.keras.Model
        }
        
        # ëª¨ë¸ ë¡œë“œ (compile=Falseë¡œ optimizer ë¬¸ì œ íšŒí”¼)
        with tf.keras.utils.custom_object_scope(custom_objects):
            # ë¨¼ì € ëª¨ë¸ êµ¬ì¡°ë§Œ ë¡œë“œ
            model = tf.keras.models.load_model(
                original_model_path,
                compile=False
            )
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ“Š ëª¨ë¸ ì •ë³´:")
        print(f"  ì…ë ¥ í˜•íƒœ: {model.input_shape}")
        print(f"  ì¶œë ¥ í˜•íƒœ: {model.output_shape}")
        print(f"  ì´ ë ˆì´ì–´: {len(model.layers)}")
        print(f"  ì´ íŒŒë¼ë¯¸í„°: {model.count_params():,}")
        
        return model, class_mapping, current_class_map
        
    except Exception as e:
        print(f"\nâŒ ê¸°ë³¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("\nëŒ€ì²´ ë°©ë²• ì‹œë„...")
        
        # ëŒ€ì²´ ë°©ë²•: ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ
        try:
            # ë¨¼ì € ë™ì¼í•œ êµ¬ì¡°ì˜ ìƒˆ ëª¨ë¸ ìƒì„±
            # EfficientNet ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •
            from tensorflow.keras.applications import EfficientNetB0
            
            base_model = EfficientNetB0(
                input_shape=(224, 224, 3),
                include_top=False,
                weights=None
            )
            
            # ì¶œë ¥ì¸µ ì¶”ê°€
            x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)
            x = tf.keras.layers.Dense(128, activation='relu')(x)
            x = tf.keras.layers.Dropout(0.2)(x)
            outputs = tf.keras.layers.Dense(5, activation='softmax')(x)
            
            model = tf.keras.Model(inputs=base_model.input, outputs=outputs)
            
            # ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œë„
            model.load_weights(original_model_path)
            print("âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ!")
            
            return model, class_mapping, current_class_map
            
        except Exception as e2:
            print(f"âŒ ëŒ€ì²´ ë°©ë²•ë„ ì‹¤íŒ¨: {e2}")
            return None, None, None

def create_remapped_model(original_model, class_mapping):
    """í´ë˜ìŠ¤ë¥¼ ì¬ë§¤í•‘í•œ ìƒˆ ëª¨ë¸ ìƒì„±"""
    
    print("\nğŸ”¨ í´ë˜ìŠ¤ ì¬ë§¤í•‘ ëª¨ë¸ ìƒì„± ì¤‘...")
    
    # ë§ˆì§€ë§‰ Dense ë ˆì´ì–´ ì°¾ê¸°
    last_dense_idx = None
    for i, layer in enumerate(original_model.layers):
        if isinstance(layer, tf.keras.layers.Dense) and layer.units == 5:
            last_dense_idx = i
            break
    
    if last_dense_idx is None:
        print("âŒ ì¶œë ¥ ë ˆì´ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return None
    
    # ìƒˆ ëª¨ë¸ ìƒì„± (ë§ˆì§€ë§‰ ë ˆì´ì–´ ì „ê¹Œì§€)
    base_output = original_model.layers[last_dense_idx - 1].output
    
    # ìƒˆë¡œìš´ ì¶œë ¥ì¸µ ìƒì„± (ì •ìƒ í´ë˜ìŠ¤ í¬í•¨í•œ 5ê°œ í´ë˜ìŠ¤)
    new_output = tf.keras.layers.Dense(
        5,
        activation='softmax',
        name='eye_disease_output'
    )(base_output)
    
    # ìƒˆ ëª¨ë¸ ìƒì„±
    new_model = tf.keras.Model(
        inputs=original_model.input,
        outputs=new_output
    )
    
    # ë§ˆì§€ë§‰ ë ˆì´ì–´ ì´ì „ê¹Œì§€ì˜ ê°€ì¤‘ì¹˜ ë³µì‚¬
    for i in range(last_dense_idx):
        try:
            new_model.layers[i].set_weights(original_model.layers[i].get_weights())
        except:
            pass
    
    # ë§ˆì§€ë§‰ ë ˆì´ì–´ ê°€ì¤‘ì¹˜ ì¬ë§¤í•‘
    original_weights = original_model.layers[last_dense_idx].get_weights()
    if len(original_weights) > 0:
        orig_w = original_weights[0]  # (input_dim, 5)
        orig_b = original_weights[1] if len(original_weights) > 1 else np.zeros(5)
        
        # ìƒˆ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (ì •ìƒ í´ë˜ìŠ¤ë¥¼ ìœ„í•œ ëœë¤ ì´ˆê¸°í™”)
        new_w = np.random.normal(0, 0.02, orig_w.shape)
        new_b = np.zeros(5)
        
        # ê¸°ì¡´ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¬ë§¤í•‘
        for orig_idx, new_idx in class_mapping.items():
            if orig_idx < orig_w.shape[1] and new_idx < new_w.shape[1]:
                new_w[:, new_idx] = orig_w[:, orig_idx]
                new_b[new_idx] = orig_b[orig_idx]
        
        # ì •ìƒ í´ë˜ìŠ¤ (ì¸ë±ìŠ¤ 0)ëŠ” ì•½ê°„ì˜ positive bias
        new_b[0] = 0.1
        
        new_model.layers[-1].set_weights([new_w, new_b])
    
    print("âœ… ì¬ë§¤í•‘ ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
    return new_model

def test_model(model, class_map):
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    test_patterns = {
        "ë¹¨ê°„ìƒ‰ (ê²°ë§‰ì—¼)": create_red_pattern(),
        "íë¦° ì¤‘ì•™ (ë°±ë‚´ì¥)": create_cloudy_center(),
        "ì •ìƒ íŒ¨í„´": create_normal_pattern()
    }
    
    for name, pattern in test_patterns.items():
        pred = model.predict(pattern, verbose=0)
        print(f"\n{name}:")
        
        # ìƒìœ„ 3ê°œ ì˜ˆì¸¡
        top_indices = np.argsort(pred[0])[-3:][::-1]
        for idx in top_indices:
            class_name = class_map.get(str(idx), f"Unknown_{idx}")
            prob = pred[0][idx]
            print(f"  {class_name}: {prob*100:.1f}%")

def create_red_pattern():
    img = np.zeros((224, 224, 3), dtype=np.float32)
    img[:, :, 0] = 0.9  # ê°•í•œ ë¹¨ê°„ìƒ‰
    img[:, :, 1] = 0.3
    img[:, :, 2] = 0.3
    return np.expand_dims(img, axis=0)

def create_cloudy_center():
    img = np.ones((224, 224, 3), dtype=np.float32) * 0.8
    center = 112
    for i in range(224):
        for j in range(224):
            dist = np.sqrt((i-center)**2 + (j-center)**2)
            if dist < 50:
                opacity = 0.9 * (1 - dist/50)
                img[i, j] = img[i, j] * (1-opacity) + np.array([0.95, 0.95, 0.95]) * opacity
    return np.expand_dims(img, axis=0)

def create_normal_pattern():
    img = np.ones((224, 224, 3), dtype=np.float32) * 0.9
    center = 112
    # ì–´ë‘ìš´ ë™ê³µ
    for i in range(224):
        for j in range(224):
            dist = np.sqrt((i-center)**2 + (j-center)**2)
            if dist < 20:
                img[i, j] = [0.1, 0.1, 0.1]
            elif dist < 50:
                img[i, j] = [0.4, 0.3, 0.2]
    return np.expand_dims(img, axis=0)

def save_converted_model(model, class_map):
    """ë³€í™˜ëœ ëª¨ë¸ ì €ì¥"""
    
    output_dir = Path("models/health_diagnosis/eye_disease")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ê¸°ì¡´ ëª¨ë¸ ë°±ì—…
    existing_models = [
        "eye_disease_fixed.h5",
        "eye_disease_tf2_complete.h5",
        "best_grouped_model.keras"
    ]
    
    for model_file in existing_models:
        model_path = output_dir / model_file
        if model_path.exists():
            backup_path = model_path.with_suffix(model_path.suffix + '.backup_before_conversion')
            import shutil
            shutil.copy(model_path, backup_path)
            print(f"ğŸ“¦ ë°±ì—…: {backup_path}")
    
    # ìƒˆ ëª¨ë¸ ì €ì¥
    print("\nğŸ’¾ ë³€í™˜ëœ ëª¨ë¸ ì €ì¥ ì¤‘...")
    
    # H5 í˜•ì‹ìœ¼ë¡œ ì €ì¥
    h5_path = output_dir / "eye_disease_converted.h5"
    model.save(h5_path, save_format='h5')
    print(f"âœ… H5 ì €ì¥: {h5_path}")
    
    # Keras í˜•ì‹ìœ¼ë¡œë„ ì €ì¥
    keras_path = output_dir / "eye_disease_converted.keras"
    model.save(keras_path)
    print(f"âœ… Keras ì €ì¥: {keras_path}")
    
    # í´ë˜ìŠ¤ë§µ ì €ì¥
    class_map_path = output_dir / "class_map.json"
    with open(class_map_path, 'w', encoding='utf-8') as f:
        json.dump(class_map, f, ensure_ascii=False, indent=2)
    print(f"âœ… í´ë˜ìŠ¤ë§µ ì €ì¥: {class_map_path}")
    
    # ë³€í™˜ ì •ë³´ ì €ì¥
    conversion_info = {
        "conversion_date": str(tf.timestamp().numpy()),
        "original_classes": {
            "0": "ê°ë§‰ ì§ˆí™˜",
            "1": "ê²°ë§‰ ë° ëˆ„ê´€ ì§ˆí™˜",
            "2": "ìˆ˜ì •ì²´ ì§ˆí™˜",
            "3": "ì•ˆê²€ ì§ˆí™˜",
            "4": "ì•ˆêµ¬ ë‚´ë¶€ ì§ˆí™˜"
        },
        "converted_classes": class_map,
        "mapping": {
            "ê°ë§‰ ì§ˆí™˜ -> ê°ë§‰ê¶¤ì–‘": "0 -> 3",
            "ê²°ë§‰ ë° ëˆ„ê´€ ì§ˆí™˜ -> ê²°ë§‰ì—¼": "1 -> 2",
            "ìˆ˜ì •ì²´ ì§ˆí™˜ -> ë°±ë‚´ì¥": "2 -> 1",
            "ì•ˆê²€ ì§ˆí™˜ -> ê¸°íƒ€ì•ˆêµ¬ì§ˆí™˜": "3 -> 4",
            "ì•ˆêµ¬ ë‚´ë¶€ ì§ˆí™˜ -> ê¸°íƒ€ì•ˆêµ¬ì§ˆí™˜": "4 -> 4",
            "(ìƒˆë¡œ ì¶”ê°€) ì •ìƒ": "-> 0"
        },
        "notes": "ì›ë³¸ ëª¨ë¸ì—ëŠ” 'ì •ìƒ' í´ë˜ìŠ¤ê°€ ì—†ì–´ì„œ ìƒˆë¡œ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ì •ìƒ í´ë˜ìŠ¤ì˜ ê°€ì¤‘ì¹˜ëŠ” ëœë¤ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
    }
    
    info_path = output_dir / "conversion_info.json"
    with open(info_path, 'w', encoding='utf-8') as f:
        json.dump(conversion_info, f, ensure_ascii=False, indent=2)
    print(f"âœ… ë³€í™˜ ì •ë³´ ì €ì¥: {info_path}")

if __name__ == "__main__":
    # 1. ì›ë³¸ ëª¨ë¸ ë¡œë“œ
    model, mapping, class_map = load_original_model_carefully()
    
    if model is None:
        print("\nâŒ ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("\nğŸ’¡ ëŒ€ì•ˆ:")
        print("1. ì›ë³¸ ëª¨ë¸ì„ TensorFlow 2.x í˜•ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì €ì¥")
        print("2. ì›ë³¸ í•™ìŠµ ì½”ë“œë¡œ ëª¨ë¸ ì¬í•™ìŠµ")
        print("3. ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ + Transfer Learning ì‚¬ìš©")
    else:
        # 2. í´ë˜ìŠ¤ ì¬ë§¤í•‘ ëª¨ë¸ ìƒì„±
        converted_model = create_remapped_model(model, mapping)
        
        if converted_model:
            # 3. ëª¨ë¸ í…ŒìŠ¤íŠ¸
            test_model(converted_model, class_map)
            
            # 4. ëª¨ë¸ ì €ì¥
            save_converted_model(converted_model, class_map)
            
            print("\nâœ… ëª¨ë¸ ë³€í™˜ ì™„ë£Œ!")
            print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
            print("1. services/eye_disease_service.py ìˆ˜ì •")
            print("   - model_pathë¥¼ 'eye_disease_converted.h5'ë¡œ ë³€ê²½")
            print("2. ì„œë²„ ì¬ì‹œì‘")
            print("3. í…ŒìŠ¤íŠ¸")
            print("\nâš ï¸  ì£¼ì˜: ì •ìƒ í´ë˜ìŠ¤ëŠ” í•™ìŠµë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤!")