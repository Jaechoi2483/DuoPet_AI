"""
ìˆ˜ì •ëœ ì•ˆêµ¬ì§ˆí™˜ ëª¨ë¸ ì² ì €í•œ ë¶„ì„
normalization ë ˆì´ì–´ ë° ê°€ì¤‘ì¹˜ ë¬¸ì œ í•´ê²° í™•ì¸
"""
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
import numpy as np
from pathlib import Path
import json
import matplotlib.pyplot as plt
import seaborn as sns

def comprehensive_model_analysis():
    """ìƒˆ ëª¨ë¸ ì¢…í•© ë¶„ì„"""
    
    print("ğŸ” ìˆ˜ì •ëœ ì•ˆêµ¬ì§ˆí™˜ ëª¨ë¸ ì¢…í•© ë¶„ì„")
    print("=" * 70)
    
    # ëª¨ë¸ ê²½ë¡œ
    model_path = Path("C:/Users/ictedu1_021/Desktop/ì•ˆêµ¬ì§ˆí™˜ëª¨ë¸/final_model_fixed.keras")
    
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return False
    
    try:
        # 1. ëª¨ë¸ ë¡œë“œ
        print("\n1ï¸âƒ£ ëª¨ë¸ ë¡œë“œ ì‹œë„...")
        print("-" * 50)
        
        # ì»¤ìŠ¤í…€ Normalization ë ˆì´ì–´
        class DummyNormalization(tf.keras.layers.Layer):
            def __init__(self, axis=-1, **kwargs):
                super().__init__(**kwargs)
                self.axis = axis
                
            def build(self, input_shape):
                super().build(input_shape)
                
            def call(self, inputs):
                return inputs  # ì…ë ¥ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
                
            def get_config(self):
                config = super().get_config()
                config.update({'axis': self.axis})
                return config
        
        # ì»¤ìŠ¤í…€ ê°ì²´ ì •ì˜
        custom_objects = {
            # Normalization ìš°íšŒ
            'Normalization': DummyNormalization,
            'normalization': DummyNormalization,
            'normalization_1': DummyNormalization,
            
            # í™œì„±í™” í•¨ìˆ˜
            'swish': tf.nn.swish,
            'Swish': tf.keras.layers.Activation(tf.nn.swish),
            
            # Dropout
            'FixedDropout': tf.keras.layers.Dropout
        }
        
        # ì»¤ìŠ¤í…€ ê°ì²´ ìŠ¤ì½”í”„ ë‚´ì—ì„œ ë¡œë“œ
        with tf.keras.utils.custom_object_scope(custom_objects):
            model = tf.keras.models.load_model(
                str(model_path),
                compile=False
            )
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ! (normalization ë¬¸ì œ í•´ê²°ë¨)")
        
        # 2. ëª¨ë¸ êµ¬ì¡° ë¶„ì„
        print("\n2ï¸âƒ£ ëª¨ë¸ êµ¬ì¡° ë¶„ì„...")
        print("-" * 50)
        print(f"ì…ë ¥ shape: {model.input_shape}")
        print(f"ì¶œë ¥ shape: {model.output_shape}")
        print(f"ì „ì²´ ë ˆì´ì–´ ìˆ˜: {len(model.layers)}")
        print(f"í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜: {model.count_params():,}")
        
        # 3. ë ˆì´ì–´ë³„ ìƒì„¸ ë¶„ì„
        print("\n3ï¸âƒ£ ì£¼ìš” ë ˆì´ì–´ ë¶„ì„...")
        print("-" * 50)
        
        # Normalization ë ˆì´ì–´ ì°¾ê¸°
        for i, layer in enumerate(model.layers):
            if 'normalization' in layer.name.lower():
                print(f"\nâœ… Normalization ë ˆì´ì–´ ë°œê²¬: {layer.name} (index: {i})")
                if hasattr(layer, 'mean') and hasattr(layer, 'variance'):
                    print("  - mean, variance ì†ì„± ì¡´ì¬")
                
        # ë§ˆì§€ë§‰ 5ê°œ ë ˆì´ì–´ ìƒì„¸ ë¶„ì„
        print("\në§ˆì§€ë§‰ 5ê°œ ë ˆì´ì–´:")
        for layer in model.layers[-5:]:
            print(f"\n{layer.name} ({layer.__class__.__name__}):")
            
            if hasattr(layer, 'units'):
                print(f"  Units: {layer.units}")
                
            if hasattr(layer, 'weights') and layer.weights:
                for weight in layer.weights:
                    w_array = weight.numpy()
                    print(f"  {weight.name}: shape={w_array.shape}")
                    
                    # ê°€ì¤‘ì¹˜ í†µê³„
                    if 'kernel' in weight.name:
                        print(f"    Mean: {np.mean(w_array):.6f}")
                        print(f"    Std: {np.std(w_array):.6f}")
                        print(f"    Min/Max: [{np.min(w_array):.6f}, {np.max(w_array):.6f}]")
                        
                    # Bias ë¶„ì„
                    if 'bias' in weight.name:
                        print(f"    Bias ê°’: {w_array}")
                        if np.all(w_array == 0):
                            print("    âš ï¸ ëª¨ë“  biasê°€ 0!")
                        else:
                            print("    âœ… Biasê°€ ì ì ˆíˆ ì´ˆê¸°í™”ë¨")
        
        # 4. ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
        print("\n4ï¸âƒ£ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸...")
        print("-" * 50)
        
        # ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
        test_cases = [
            ("ë°±ìƒ‰ ì´ë¯¸ì§€", np.ones((1, 224, 224, 3), dtype=np.float32)),
            ("í‘ìƒ‰ ì´ë¯¸ì§€", np.zeros((1, 224, 224, 3), dtype=np.float32)),
            ("ëœë¤ ì´ë¯¸ì§€", np.random.random((1, 224, 224, 3)).astype(np.float32)),
            ("ë¹¨ê°„ìƒ‰ ì´ë¯¸ì§€", np.zeros((1, 224, 224, 3), dtype=np.float32)),
            ("íŒŒë€ìƒ‰ ì´ë¯¸ì§€", np.zeros((1, 224, 224, 3), dtype=np.float32)),
            ("ë…¸ë€ìƒ‰ ì´ë¯¸ì§€", np.zeros((1, 224, 224, 3), dtype=np.float32))
        ]
        
        # ìƒ‰ìƒ ì„¤ì •
        test_cases[3][1][:,:,:,0] = 1.0  # Red
        test_cases[4][1][:,:,:,2] = 1.0  # Blue  
        test_cases[5][1][:,:,:,0] = 1.0  # Yellow
        test_cases[5][1][:,:,:,1] = 1.0
        
        predictions = []
        for name, test_input in test_cases:
            pred = model.predict(test_input, verbose=0)
            predictions.append(pred[0])
            
            print(f"\n{name}:")
            print(f"  ì˜ˆì¸¡ê°’: {pred[0]}")
            print(f"  í™•ë¥ (%): {[f'{p*100:.1f}' for p in pred[0]]}")
            print(f"  ìµœê³  í™•ë¥  í´ë˜ìŠ¤: {np.argmax(pred[0])} ({np.max(pred[0])*100:.1f}%)")
            
            # ë™ì¼ í™•ë¥  ì²´í¬
            if np.allclose(pred[0], pred[0][0], rtol=1e-3):
                print("  âš ï¸ ëª¨ë“  í´ë˜ìŠ¤ í™•ë¥ ì´ ë™ì¼!")
            else:
                print("  âœ… í´ë˜ìŠ¤ë³„ í™•ë¥ ì´ ë‹¤ë¦„ (ì •ìƒ)")
        
        # 5. ì˜ˆì¸¡ ë¶„í¬ ë¶„ì„
        print("\n5ï¸âƒ£ ì˜ˆì¸¡ ë¶„í¬ ë¶„ì„...")
        print("-" * 50)
        
        predictions_array = np.array(predictions)
        
        # ê° í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ í†µê³„
        class_map = {
            "0": "ê°ë§‰ ì§ˆí™˜",
            "1": "ê²°ë§‰ ë° ëˆ„ê´€ ì§ˆí™˜",
            "2": "ìˆ˜ì •ì²´ ì§ˆí™˜",
            "3": "ì•ˆê²€ ì§ˆí™˜",
            "4": "ì•ˆêµ¬ ë‚´ë¶€ ì§ˆí™˜"
        }
        
        print("\ní´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ í†µê³„:")
        for i in range(5):
            class_preds = predictions_array[:, i]
            print(f"\n{class_map[str(i)]}:")
            print(f"  í‰ê· : {np.mean(class_preds):.3f}")
            print(f"  í‘œì¤€í¸ì°¨: {np.std(class_preds):.3f}")
            print(f"  ìµœì†Œ/ìµœëŒ€: [{np.min(class_preds):.3f}, {np.max(class_preds):.3f}]")
        
        # 6. ëª¨ë¸ ê±´ê°•ë„ ì¢…í•© í‰ê°€
        print("\n6ï¸âƒ£ ëª¨ë¸ ê±´ê°•ë„ ì¢…í•© í‰ê°€...")
        print("-" * 50)
        
        health_checks = {
            "ëª¨ë¸ ë¡œë“œ": True,
            "Normalization ë ˆì´ì–´": any('normalization' in l.name.lower() for l in model.layers),
            "ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”": not all(np.allclose(p[0], p[0][0]) for p in predictions),
            "Bias í™œì„±í™”": not any(np.all(w.numpy() == 0) for l in model.layers[-5:] 
                                  for w in l.weights if 'bias' in w.name),
            "ì˜ˆì¸¡ ë‹¤ì–‘ì„±": np.std(predictions_array) > 0.05
        }
        
        print("\nê±´ê°•ë„ ì²´í¬ë¦¬ìŠ¤íŠ¸:")
        for check, status in health_checks.items():
            print(f"  {'âœ…' if status else 'âŒ'} {check}")
        
        # ì¢…í•© íŒì •
        if all(health_checks.values()):
            print("\nğŸ‰ ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
            
            # ëª¨ë¸ ì •ë³´ ì €ì¥
            model_info = {
                "model_path": str(model_path),
                "input_shape": model.input_shape,
                "output_shape": model.output_shape,
                "num_layers": len(model.layers),
                "num_params": int(model.count_params()),
                "health_checks": health_checks,
                "class_map": class_map
            }
            
            with open("models/health_diagnosis/eye_disease/model_info.json", "w", encoding="utf-8") as f:
                json.dump(model_info, f, ensure_ascii=False, indent=2)
            
            print("\nâœ… ëª¨ë¸ ì •ë³´ ì €ì¥ ì™„ë£Œ: model_info.json")
            return True
        else:
            print("\nâš ï¸ ì¼ë¶€ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return False
            
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = comprehensive_model_analysis()
    
    if success:
        print("\n\nâœ… ë¶„ì„ ì™„ë£Œ! ëª¨ë¸ì„ í”„ë¡œì íŠ¸ì— í†µí•©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("\në‹¤ìŒ ë‹¨ê³„:")
        print("1. ëª¨ë¸ íŒŒì¼ ë³µì‚¬")
        print("2. ì„œë¹„ìŠ¤ ì½”ë“œ ì—…ë°ì´íŠ¸")
        print("3. í†µí•© í…ŒìŠ¤íŠ¸")
    else:
        print("\n\nâŒ ëª¨ë¸ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")